{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SVM and kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c7b8f71403aa9084",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Kernels concept get adopted in variety of ML algorithms (e.g. Kernel PCA, Gaussian Processes, kNN, ...).\n",
    "\n",
    "So in this task you are to examine kernels for SVM algorithm applied to rather simple artificial datasets.\n",
    "\n",
    "To make it clear: we will work with the classification problem through the whole notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:22.240114Z",
     "start_time": "2019-03-13T23:26:21.327520Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57f562bf4f554fae",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b128784928e8df1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Let's generate our dataset and take a look on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:22.247247Z",
     "start_time": "2019-03-13T23:26:22.242895Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee8cf8e9cf114b9d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "moons_points, moons_labels = make_moons(n_samples=500, noise=0.2, random_state=42)\n",
    "plt.scatter(moons_points[:, 0], moons_points[:, 1], c=moons_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-35b09404d22ab9f4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 1.1 Pure models.\n",
    "First let's try to solve this case with good old Logistic Regression and simple (linear kernel) SVM classifier.\n",
    "\n",
    "Train LR and SVM classifiers (choose params by hand, no CV or intensive grid search neeeded) and plot their decision regions. Calculate one preffered classification metric.\n",
    "\n",
    "Describe results in one-two sentences.\n",
    "\n",
    "_Tip:_ to plot classifiers decisions you colud use either sklearn examples ([this](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_alpha.html#sphx-glr-auto-examples-neural-networks-plot-mlp-alpha-py) or any other) and mess with matplotlib yourself or great [mlxtend](https://github.com/rasbt/mlxtend) package (see their examples for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decisions(X, y, clf):\n",
    "    clf.fit(X, y)\n",
    "    plot_decision_regions(X, y, clf=clf)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:22.846438Z",
     "start_time": "2019-03-13T23:26:22.482543Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-550546e70e191bc3",
     "locked": false,
     "points": 10,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "lr = LogisticRegression(penalty = 'l2', C = 1.5) # add some params\n",
    "svm = SVC(kernel='linear', C = 3) # here too\n",
    "\n",
    "names = ['Logistic Regression','SVM']\n",
    "i = 0  \n",
    "for clf in [lr, svm]:\n",
    "    print(str(names[i])) \n",
    "    plot_decisions(moons_points, moons_labels, clf)\n",
    "    print(str(names[i]) + ' score = ' + str(roc_auc_score(clf.predict(moons_points), moons_labels))) \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Kernel tirck\n",
    "\n",
    "Now use different kernels (`poly`, `rbf`, `sigmoid`) on SVC to get better results. Play `degree` parameter and others.\n",
    "\n",
    "For each kernel estimate optimal params, plot decision regions, calculate metric you've chosen eariler.\n",
    "\n",
    "Write couple of sentences on:\n",
    "\n",
    "* What have happenned with classification quality?\n",
    "* How did decision border changed for each kernel?\n",
    "* What `degree` have you chosen and why?\n",
    "\n",
    "__Note__:\n",
    "In this part we will use [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), which is capable of iteratively fitting the selected model with different sets of hyperparameters and perform its evaluaiton using cross-validation over the provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:22.864832Z",
     "start_time": "2019-03-13T23:26:22.862013Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3a1681e6d52ed236",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# <YOUR CODE HERE>\n",
    "parameters_grid = {\n",
    "    # describe the parameter grid as pairs - parameter_name: parameter range\n",
    "}\n",
    "\n",
    "parameters_grid_poly = {\n",
    "    # describe the parameter grid as pairs - parameter_name: parameter range\n",
    "}\n",
    "\n",
    "# use SVC() and the necessary kernel\n",
    "svm_p = \n",
    "svm_r = \n",
    "svm_s = \n",
    "\n",
    "# use grid search with 3-fold cross validation and the necessary parameter grid\n",
    "grid_cv_r = GridSearchCV()\n",
    "grid_cv_s = GridSearchCV()\n",
    "grid_cv_p = GridSearchCV()\n",
    "\n",
    "grid_cv_r.fit(moons_points, moons_labels)\n",
    "grid_cv_s.fit(moons_points, moons_labels)\n",
    "grid_cv_p.fit(moons_points, moons_labels)\n",
    "\n",
    "# print best params and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the decision boundaries for SVM with the used kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba9a59e3ec57f514",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 1.3 Simpler solution (of a kind)\n",
    "What is we could use Logisitc Regression to successfully solve this task?\n",
    "\n",
    "Feature generation is a thing to help here. Different techniques of feature generation are used in real life, couple of them will be covered in additional lectures.\n",
    "\n",
    "In particular case simple `PolynomialFeatures` ([link](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)) are able to save the day.\n",
    "\n",
    "Generate the set of new features, train LR on it, plot decision regions, calculate metric.\n",
    "\n",
    "* Compare SVM's results with this solution (quality, borders type)\n",
    "* What degree of PolynomialFeatures have you used? Compare with same SVM kernel parameter.\n",
    "\n",
    "__Note__:\n",
    "In this part we will use scikit-learn [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class, which is capable of combining a set of pre-processing methods for the used dataset and fitting an estimator in the end. It is very useful for preprocessing functions, which parameters are estimated during training phase and used without change during testing phase. Moreover, pipelines allow for simpler grid search and cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:22.869584Z",
     "start_time": "2019-03-13T23:26:22.866757Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-58a1e03cab2ca349",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "lr = LogisticRegression(<set the parameters as you wish>)\n",
    "poly = PolynomialFeatures(degree = 3)\n",
    "\n",
    "pipeline = Pipeline(steps = [('poly', poly), ('regression', lr)])\n",
    "pipeline.fit(moons_points, moons_labels)\n",
    "plot_decision_regions(moons_points, moons_labels, clf=pipeline)\n",
    "\n",
    "print(' score = ' + str(roc_auc_score(pipeline.predict(moons_points), moons_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-868839a4a8358c59",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 1.4 Bonus area: Harder problem\n",
    "\n",
    "Let's make this task a bit more challenging via upgrading dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:23.084319Z",
     "start_time": "2019-03-13T23:26:22.876842Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86be614f32559cea",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "circles_points, circles_labels = make_circles(n_samples=500, noise=0.06, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(circles_points[:, 0], circles_points[:, 1], c=circles_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e7e5a8e0da66afbe",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "And even more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:23.326325Z",
     "start_time": "2019-03-13T23:26:23.086480Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7a98ef8e43822e61",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "points = np.vstack((circles_points*2.5 + 0.5, moons_points))\n",
    "labels = np.hstack((circles_labels, moons_labels + 2)) # + 2 to distinct moons classes\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(points[:, 0], points[:, 1], c=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7c2a785a2d63ce73",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now do your best using all the approaches above!\n",
    "\n",
    "Tune LR with generated features, SVM with appropriate kernel of your choice. You may add some of your loved models to demonstrate their (and your) strength. Again plot decision regions, calculate metric.\n",
    "\n",
    "Justify the results in a few phrases.\n",
    "\n",
    "__Note__:\n",
    "Don't forget, that we are dealing with multi-class classification, so we need to select the multi-class strategy (one-vs-rest or one-vs-one) and adjust our models accordingly.\n",
    "\n",
    "The simplest way to do so is to use scikit-learn [multiclass](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.multiclass).\n",
    "You may use [OneVsRestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html) or [OneVsOneClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier) classes respectively to wrap your target model class.\n",
    "\n",
    "The resulting model will be ready to fit and predict for multi-class dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:23.330584Z",
     "start_time": "2019-03-13T23:26:23.328232Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e61b36ea61909c83",
     "locked": false,
     "points": 40,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "labels_bin = label_binarize(labels, classes=[0, 1, 2, 3])\n",
    "\n",
    "parameters_grid = {\n",
    "}\n",
    "\n",
    "parameters_grid_poly = {\n",
    "}\n",
    "\n",
    "parameters_grid_sigmoid = {\n",
    "}\n",
    "\n",
    "svm_p = OneVsRestClassifier()\n",
    "svm_r = OneVsRestClassifier()\n",
    "svm_s = OneVsRestClassifier()\n",
    "\n",
    "# use grid search with 3-fold cross-validation and 'accuracy' score for best model selection\n",
    "grid_cv_r = \n",
    "grid_cv_s = \n",
    "grid_cv_p = \n",
    "\n",
    "grid_cv_r.fit(points, labels_bin)\n",
    "grid_cv_s.fit(points, labels_bin)\n",
    "grid_cv_p.fit(points, labels_bin)\n",
    "\n",
    "print('rbf: best params: ' + str(grid_cv_r.best_params_) + ' score: ' + str(grid_cv_r.best_score_))\n",
    "print('sigmoid: best params: ' + str(grid_cv_s.best_params_) + ' score: ' + str(grid_cv_s.best_score_))\n",
    "print('poly: best params: ' + str(grid_cv_p.best_params_) + ' score: ' + str(grid_cv_p.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression supports multi-class targets by desing in scikit-learn, so we just need to set the proper multi-class strategy type.\n",
    "\n",
    "We advise to select 'multinomial' type, so the model loss is fit across the entire probability distribution, instead of having several 'one-versus-rest' losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression\n",
    "poly = PolynomialFeatures()\n",
    "lr = LogisticRegression(multi_class='multinomial', solver = 'saga', max_iter = 5000)\n",
    "pipeline = # select pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid = {\n",
    "    # set up parameter grid for the logistic regression pipeline\n",
    "}\n",
    "\n",
    "# use grid search with 3-fold cross-validation and 'accuracy' score for best model selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)\n",
    "plot_decisions(points, labels, grid_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: \n",
    "\n",
    "Try to describe the obtained results.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
